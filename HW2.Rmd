---
title: "homework1"
author: "Bernardo Magalhaes, Adhish Luitel, Ji Heon Shim"
date: "`r format(Sys.Date())`" 
always_allow_html: true
output:
    md_document:
    variant: markdown_github
---
#ECO 395M: Exercise 2

Bernardo Arreal Magalhaes - UTEID ba25727

Adhish Luitel - UTEID al49674

Ji Heon Shim - UTEID js93996

## Exercise 2.2
```{r setup1, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dummies)
library(margins)
library(dplyr)
library(kableExtra)
library(sjPlot)
library(mosaic)

brca = read.csv(url("https://raw.githubusercontent.com/bmagalhaes/ECO395M-HW2/master/brca.csv"))
```
This exercise is based on a dataset consisted of 987 screening mammograms administered at a hospital in Seattle, Washington. The goal of the analysis is to evaluate the performance of five different radiologists considering several risk factors.

First, we analyzed the raw data to verify whether each radiologist has a different recall rate or not, and compare precision and error rates. We can observe that, even though radiologist89 has a higher probability of recalling patients, his Type II error rate (not recalling patients that actually have cancer) doesn't substantially differ from radiologist95 and radiologist34, who have the lowest recall rates.

```{r 2.2.1, echo=FALSE}
recall_rate = brca %>%
  group_by(radiologist)  %>%
  summarize(A.recallrate = length(which(recall == 1)) / (length(which(recall == 1))
            + length(which(recall == 0))))

recall_rate = recall_rate[order(-recall_rate$A.recallrate),c(1,2)]
recall_rate = mutate(recall_rate, n = row_number())

cancer_rate = brca %>%
  group_by(radiologist)  %>%
  summarize(B.cancerrate = length(which(recall == 1 & cancer == 1)) / (length(which(recall == 1 & 
            cancer == 1)) + length(which(recall == 1 & cancer == 0))))

error_rate = brca %>%
  group_by(radiologist)  %>%
  summarize(C.error = length(which(recall == 0 & cancer == 1)) / (length(which(recall == 0 & 
            cancer == 1)) + length(which(recall == 0 & cancer == 0))))

radiologist = left_join(recall_rate, cancer_rate, by = "radiologist")
radiologist = left_join(radiologist, error_rate, by = "radiologist")

radiologist_long = radiologist %>%
  gather("Stat", "Value", -radiologist, -n)
radiologist_long = mutate(radiologist_long, Value = Value*100)

radiologist_89 = radiologist_long[which(radiologist_long$n==1), ]

ggplot(data = radiologist_long) + 
  geom_bar(mapping = aes(x=reorder(radiologist, -n), y=Value),
           stat='identity', position ='dodge', fill="lightgray", color="black", alpha=.6, width=.5) + 
  facet_wrap(~Stat) + 
  coord_flip() +
  labs(y="Observed rate (in percentage)", x = "") +
  geom_hline(data= radiologist_89, aes(yintercept=Value), color="red" , linetype = "dashed") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5), panel.grid.major.y = element_blank(), panel.grid.minor.y = element_blank()) 
```

However, since each radiologist read the mammograms of a different set of patients, this difference could be explained by the fact that some radiologists might have seen patients whose clinical situation required the patient to be recalled for further examination.

In order to analyse if, holding patient risk factors equal, some radiologists are more clinically conservative than others in recalling patients, we built two classification models:

```{r 2.2.2, echo=TRUE}
model1 = recall ~ radiologist + age + history + symptoms + menopause + density
model2 = recall ~ (age + history + symptoms + menopause + density) * radiologist
```

The table below shows the Average Marginal Effect (AME) for each radiologist in the two models. We can see that, when using Model 1, radiologist89 is the most conservative - holding patient risk factors equal, the probability of being recalled increases by 5.71 percentage points when radiologist89 is the one reading the mammogram compared to the baseline radiologist13.

When allowing for interactions between radiologist and each control variable as in Model 2, radiologist89 is still the most conservative - holding patient risk factors equal, the probability of being recalled increases by 17.48 percentage points when radiologist89 is the one reading the mammogram compared to the baseline radiologist13.

```{r 2.2.3, echo=FALSE, warning = FALSE}
brca2 = brca
brca2$radiologist = str_replace(brca2$radiologist, "radiologist","")
brca2$age = str_replace(brca2$age, "age","")
brca2$menopause = str_replace(brca2$menopause, "meno","")
brca2$density = str_replace(brca2$density, "density","")

brca_new = dummy.data.frame(brca2, names = c("radiologist", "age","menopause", "density") , sep = ".")
brca_new = subset(brca_new, select = -c(radiologist.13, age.4049,menopause.postHT, density.1))

model_1 = glm(recall ~ . - cancer, data=brca_new, family=binomial)
ame_11 = summary(margins(model_1, variables = list("radiologist.34", "radiologist.66", "radiologist.89", "radiologist.95"), vce = "bootstrap"))

model_2 = glm(recall ~ (history + symptoms + age.5059 + age.6069 + age.70plus + menopause.postNoHT
              + menopause.postunknown + menopause.pre + density.2 + density.3 + density.4)*(radiologist.34
              + radiologist.66 + radiologist.89 + radiologist.95), data=brca_new, family=binomial)
ame_21 = summary(margins(model_2, variables = list("radiologist.34", "radiologist.66", "radiologist.89", "radiologist.95"), vce = "bootstrap"))

ame_11 = select(ame_11,-c(4:7))
ame_21 = select(ame_21,-c(4:7))

ame = left_join(ame_11, ame_21, by = "factor")
colnames(ame) <- c("","AME","se","AME","se")

kable(ame) %>%
  kable_styling("striped") %>%
  add_header_above(c(" " = 1, "Model 1" = 2, "Model 2" = 2))
```

Finally, in order to estimate how each radiologist would perform when facing the same set of patients, we used a bootstrap to randomly split the original dataset in a training dataset containing 80% of the observations and a testing a dataset containing 20% of the observations, repeating the proccess 100 times. In each repetition, we fitted both models using the train dataset, and compared each model's predictions when all radiologists, in a hypothetical scenario, analyze the entire test dataset. 

We computed average probability of recall per repetition, and calculated the average of the 100 samples to mitigate the effect of randomization. For both models, radiologist89 has the highest probability of recall, followed by radiologist66, radiologist13, radiologist95 and radiologist 34.


```{r 2.2.4, echo=FALSE, warning = FALSE}
n = nrow(brca_new)

boot1 = do(100)*{
  
  # re-split into train and test cases
  n_train = round(0.8*n)  # round to nearest integer
  n_test = n - n_train
  train_cases = sample.int(n, n_train, replace=FALSE)
  test_cases = setdiff(1:n, train_cases)
  brca_train = brca_new[train_cases,]
  brca_test = brca_new[test_cases,]
  brca_test = brca_test[rep(seq_len(nrow(brca_test)), 5),]
  brca_test =  brca_test %>%
    mutate(n = row_number()) %>%
    mutate(radiologist.34 = 0) %>%
    mutate(radiologist.66 = 0) %>%
    mutate(radiologist.89 = 0) %>%
    mutate(radiologist.95 = 0)
  brca_test = brca_test %>%
    mutate(radiologist.34 = ifelse(n > nrow(brca_test)/5 & nrow(brca_test)*2/5 >= n, 1, 0)) %>%
    mutate(radiologist.66 = ifelse(n > nrow(brca_test)*2/5 & nrow(brca_test)*3/5 >= n, 1, 0)) %>%
    mutate(radiologist.89 = ifelse(n > nrow(brca_test)*3/5 & nrow(brca_test)*4/5 >= n, 1, 0)) %>%
    mutate(radiologist.95 = ifelse(n > nrow(brca_test)*4/5 & nrow(brca_test) >= n, 1, 0))
 
  # fit to this training set
  glm_1 = glm(recall ~ . - cancer, data=brca_train, family=binomial)
  glm_2 = glm(recall ~ (history + symptoms + age.5059 + age.6069 + age.70plus + menopause.postNoHT
                        + menopause.postunknown + menopause.pre + density.2 + density.3 + density.4)*(radiologist.34
                        + radiologist.66 + radiologist.89 + radiologist.95), data=brca_train, family=binomial)
  
  # predict on this testing set
  yhat_test1 = predict(glm_1, brca_test, type="response")
  yhat_test2 = predict(glm_2, brca_test, type="response")
  brca_test = brca_test %>%
    mutate(radiologist = ifelse(radiologist.34 == 1, "radiologist.34",
                         ifelse(radiologist.66 == 1, "radiologist.66",
                         ifelse(radiologist.89 == 1, "radiologist.89",
                         ifelse(radiologist.95 == 1, "radiologist.95", "radiologist.13")))))
  
  brca_test$pred1 = yhat_test1
  brca_test$pred2 = yhat_test2
  recalls_1 = brca_test %>%
    group_by(radiologist)  %>%
    summarize(recalls = mean(pred1))
  recalls_2 = brca_test %>%
    group_by(radiologist)  %>%
    summarize(recalls = mean(pred2))
  recalls_t = rbind(recalls_1, recalls_2)
  recalls = as.data.frame(t(recalls_t))
  recalls = recalls[-1, ]
  colnames(recalls) <- c("M1_radiologist.13", "M1_radiologist.34", "M1_radiologist.66", 
                         "M1_radiologist.89", "M1_radiologist.95", "M2_radiologist.13",
                         "M2_radiologist.34", "M2_radiologist.66", 
                         "M2_radiologist.89", "M2_radiologist.95")
  recalls
  }

boot1[, c(1:10)] = sapply(boot1[, c(1:10)], as.numeric)

radiologist = c("radiologist.13", "radiologist.34", "radiologist.66", "radiologist.89", "radiologist.95")
Model_1 = c(mean(boot1$M1_radiologist.13), mean(boot1$M1_radiologist.34), mean(boot1$M1_radiologist.66),
       mean(boot1$M1_radiologist.89), mean(boot1$M1_radiologist.95))
Model_2 = c(mean(boot1$M2_radiologist.13), mean(boot1$M2_radiologist.34), mean(boot1$M2_radiologist.66),
       mean(boot1$M2_radiologist.89), mean(boot1$M2_radiologist.95))
a = data.frame(radiologist, Model_1,Model_2)

kable(a) %>%
  kable_styling("striped") %>%
  add_header_above(c(" " = 1, "(Out of sample) Average recall probability" = 2))
```

After that, we analyzed if the data suggest that radiologists at this hospital should be weighting some clinical risk factors more heavily than they currently are when interpreting mammograms in order to make a decision on whether to recall a patient or not.

We started by stablishing the following baseline model.

```{r 2.2.5, echo=TRUE}
baseline_model = cancer ~ recall
```

Then, we built multiple models adding each of the clinical risk factors to the baseline model.

```{r 2.2.6, echo=TRUE}
baseline_history_model = cancer ~ recall + history
baseline_age_model = cancer ~ recall + age
baseline_symptoms_model = cancer ~ recall + symptoms
baseline_menopause_model = cancer ~ recall + menopause
baseline_density_model = cancer ~ recall + density
```

If the radiologists were appropriately accounting for the clinical risk factors when deciding whether to recall a patient for further examination, we would expect the coefficient associated with the recall variable to capture this effect, and the coefficient of the control variable to be close to zero (so the odds ratio to be close to one). Hence, including this variables in the model shouldn't considerably affect the cancer predictions.

The table below summarizes the estimates from the 6 models. Here, we observe that age 70 or plus, density 4 (extremely dense) and post-menopausal/unknown hormone-therapy status are some factors that are increasing the odds of having a cancer, even after medical analysis! Thus there's extra information in the risk factors that the doctors should be weighting more heavily to recall patients than they currently are.

```{r 2.2.7, echo=FALSE, warning = FALSE}
model_cancer = glm(cancer ~ recall, data=brca, family=binomial)
model_cancer2 = glm(cancer ~ recall + history, data=brca, family=binomial)
model_cancer3 = glm(cancer ~ recall + age, data=brca, family=binomial)
model_cancer4 = glm(cancer ~ recall + symptoms, data=brca, family=binomial)
model_cancer5 = glm(cancer ~ recall + menopause, data=brca, family=binomial)
model_cancer6 = glm(cancer ~ recall + density, data=brca, family=binomial)

tab_model(model_cancer, model_cancer2, model_cancer3, model_cancer4, model_cancer5,
          model_cancer6, show.ci = FALSE, show.p = TRUE,
          dv.labels = c("Baseline Model", "+History", "+Age", "+Symptoms",
                        "+Menopause", "+Density"))
```

Considering the results above, we built a new model including those 3 risk factors.

```{r 2.2.8, echo=TRUE}
proposed_model = cancer ~ recall + age.70plus + postmenounknown + density.4
```

In order to assess how well this model performs when predicting cancer status, we need to compare its predictions with the predictions from the baseline model.

The confusion matrix for the baseline model below shows that the doctors are currently predicting cancer with a 59.46% sensitivity (22/(22+15)) and a accuracy rate of 85.71% ((824+22)/987).

```{r 2.2.9, echo=FALSE, warning = FALSE}
xtabs(~cancer + recall, data=brca)
```

Considering the in-sample probability of cancer as a threshold for the fitted values of the proposed model to predict cancer or not, we computed the following confusion matrix. This matrix show that, when including age.70plus, postmenounknown and density.4 in the model, the sensitivity increased to 64.86 (24/(13+24)) and the accuracy rate slightly decreased to 84.60% ((811+24)/987).

```{r 2.2.10, echo=FALSE, warning = FALSE}
model_cancer7 = glm(cancer ~ recall + age.70plus + menopause.postunknown + density.4, data=brca_new, family=binomial)
yhat_7 = predict(model_cancer7, brca_new, type="response")
prob_cancer = sum(brca_new$cancer == 1)/nrow(brca_new)
yhat_test7 = ifelse(yhat_7 >= prob_cancer, 1, 0)
table(y=brca_new$cancer, yhat=yhat_test7)
```

Since a cancer that is diagnosed at an early stage is more likely to be treated successfully, it is reasonable to argue that the increase in sensitivity overcomes the decrease in the accuracy rates caused by a higher amount of false positive predictions. Hence, our best judgement is that the radiologists should be weighting more heavily patients with 70 years old and above, density 4 (extremely dense) and post-menopausal/unknown hormone-therapy status when deciding whether to recall patients.