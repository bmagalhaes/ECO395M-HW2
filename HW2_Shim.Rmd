---
title: "homework2"
author: "Bernardo Magalhaes, Adhish Luitel, Ji Heon Shim"
date: "`r format(Sys.Date())`" 
always_allow_html: true
output:
    md_document:
    variant: markdown_github
---
#ECO 395M: Exercise 2

Bernardo Arreal Magalhaes - UTEID ba25727

Adhish Luitel - UTEID al49674

Ji Heon Shim - UTEID js93996

## Exercise 2.1
```{r setup1, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dummies)
library(margins)
library(dplyr)
library(kableExtra)
library(sjPlot)
library(mosaic)
library(FNN)
library(foreach)
data(SaratogaHouses)
```
In this exercise, we hand-build five models for price in order to find out the best one which outperforms the "medium" model that we considered in class.

```{r 2.1.1, echo= TRUE, warning = FALSE}
model1= price ~ lotSize + age + landValue + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + heating + fuel + sewer + waterfront + newConstruction + centralAir 
model2= price~ lotSize + age + landValue + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + heating + fuel + centralAir 
model3= price~ (lotSize + age + landValue + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + heating + fuel + centralAir)^2 
model4= price~ lotSize + age +pctCollege * landValue + livingArea * (bedrooms + bathrooms) + fireplaces + heating + fuel + centralAir
model5= price~ lotSize + age + age2 + pctCollege * landValue + livingArea * (bedrooms + bathrooms) + fireplaces + heating + fuel + centralAir

model_medium = price ~ lotSize + age + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + rooms + heating + fuel + centralAir

```

Here are the main features of our models.

Model 1 : include all main effects except roooms
(exclude rooms because of colinearity, rooms = bedrooms + batherooms)
Model 2: simplify model1 by reducing some variables(-sewer-waterfront-newConstruction)
Model 3: add all the interactions on model 2
Model 4: allow only some interactions on model 2
Model 5: a polynomial model by adding age^2 on model 4
Model_medium: baseline model with 11 main effects

             
```{r 2.1.2, echo=FALSE}
# make a new variable age2=(age)^2
SaratogaHouses <- mutate(SaratogaHouses, age2=(age)^2)

rmse = function(y, yhat) {
  sqrt( mean( (y - yhat)^2 ) )
}
```

In order to measure performances of each model, we run Monte Carlo training-test split(train 80%, test 20%) for 100 times and calcaulate the average values of out-of-sample RMSE for each model.


```{r 2.1.3, echo=FALSE, warning=FALSE}
rmse_check = do(100)*{# Split into training and testing sets
n = nrow(SaratogaHouses)
n_train = round(0.8*n)  # round to nearest integer
n_test = n - n_train
train_cases = sample.int(n, n_train, replace=FALSE)
test_cases = setdiff(1:n, train_cases)
saratoga_train = SaratogaHouses[train_cases,]
saratoga_test = SaratogaHouses[test_cases,]

#Hand-build some models and fit into training data

# model1: use all possible variables except rooms and age2 without interactions
# we get rid of "rooms" because of collinearity, rooms=bathrooms+bedrooms)
model1= lm(price ~ .-rooms-age2, data=saratoga_train)

# model2: simplify model1 by deleting some variables that look unimportant
# sewer(unimportant), waterfront, newConstruction(not enough samples with value of 1)
model2= lm(price~ .-rooms-sewer-waterfront-newConstruction-age2, data=saratoga_train)

# model3 : add all the interactions on model2
model3= lm(price~ (.-rooms-sewer-waterfront-newConstruction-age2)^2, data=saratoga_train)

# model4: allow only some interactions
model4= lm(price~ lotSize + age +pctCollege * landValue + livingArea * (bedrooms + bathrooms) + fireplaces + heating + fuel + centralAir, data=saratoga_train)

# add a new variables for polynomial regression on model4
# we added age^2 because it is likely that house price rapidly goes down as it becomes aged

model5= lm(price~ lotSize + age + age2 + pctCollege * landValue + livingArea * (bedrooms + bathrooms) + fireplaces + heating + fuel + centralAir, data=saratoga_train)

# our baseline model, medium
model_medium = lm(price ~ lotSize + age + livingArea + pctCollege + bedrooms + 
                 fireplaces + bathrooms + rooms + heating + fuel + centralAir, data=saratoga_train)

# Predictions out of sample
yhat_test1 = predict(model1, saratoga_test)
yhat_test2 = predict(model2, saratoga_test)
yhat_test3 = predict(model3, saratoga_test)
yhat_test4 = predict(model4, saratoga_test)
yhat_test5 = predict(model5, saratoga_test)
yhat_test_medium = predict(model_medium, saratoga_test)

c(rmse(saratoga_test$price, yhat_test1), rmse(saratoga_test$price, yhat_test2), rmse(saratoga_test$price, yhat_test3), rmse(saratoga_test$price, yhat_test4), rmse(saratoga_test$price, yhat_test5), rmse(saratoga_test$price, yhat_test_medium))}

rmse_result= data.frame("model1"= colMeans(rmse_check[1]), "model2"=colMeans(rmse_check[2]), "model3"=colMeans(rmse_check[3]), "model4"=colMeans(rmse_check[4]), "model5"=colMeans(rmse_check[5]), "model_medium"=colMeans(rmse_check[6]), row.names="AVG_RMSE")

kable(rmse_result) %>% kable_styling("striped")

```


The best model turned out to be model 1 with the least out-of-sample RMSE value. Here is the summary of model 1.

```{r 2.1.4, echo=TRUE}
summary(model1)

```

And we can find the variable which is the strongest driver of house prices by assessing how much it improves the out-of-sample RMSE when it is included in the model.
So we test how much the out-of-sample increases when we exclude a certain variable from our model 1, and get the average RMSE by doing Monte Carlo simulation on different training-test sets(80%-20%) for 100 times.

As the table below shows, "landValue" variable seems to be the storngest drive of house prices. This result might be caused because land values are already included in house prices(House price = Land value + Pure house value), so they are strongly related to each other.


```{r 2.1.5, echo=FALSE, warning=FALSE}
rmse_check2 = do(100)*{# Split into training and testing sets
train_cases2 = sample.int(n, n_train, replace=FALSE)
test_cases2 = setdiff(1:n, train_cases)
saratoga_train2 = SaratogaHouses[train_cases2,]
saratoga_test2 = SaratogaHouses[test_cases2,]

#Hand-build some models and fit into training data

# model1_wo_lotSize: without lotSize
model1_wo_lotSize= lm(price ~ .-rooms-age2-lotSize, data=saratoga_train2)

# model1_wo_age: without age
model1_wo_age= lm(price ~ .-rooms-age2-age, data=saratoga_train2)

# model1_wo_landValue: without landValue
model1_wo_landValue= lm(price ~ .-rooms-age2-landValue, data=saratoga_train2)

# model1_wo_livingArea: without livingArea
model1_wo_livingArea= lm(price ~ .-rooms-age2-livingArea, data=saratoga_train2)

# model1_wo_pctCollege: without pctCollege
model1_wo_pctCollege= lm(price ~ .-rooms-age2-pctCollege, data=saratoga_train2)

# model1_wo_bedrooms: without bedrooms
model1_wo_bedrooms= lm(price ~ .-rooms-age2-bedrooms, data=saratoga_train2)

# model1_wo_fireplaces: without fireplaces
model1_wo_fireplaces= lm(price ~ .-rooms-age2-fireplaces, data=saratoga_train2)

# model1_wo_bathrooms: without bathrooms
model1_wo_bathrooms= lm(price ~ .-rooms-age2-bathrooms, data=saratoga_train2)

# model1_wo_heating: without heating
model1_wo_heating= lm(price ~ .-rooms-age2-heating, data=saratoga_train2)

# model1_wo_fuel: without fuel
model1_wo_fuel= lm(price ~ .-rooms-age2-fuel, data=saratoga_train2)

# model1_wo_sewer: without sewer
model1_wo_sewer= lm(price ~ .-rooms-age2-sewer, data=saratoga_train2)

# model1_wo_waterfront: without waterfront
model1_wo_waterfront= lm(price ~ .-rooms-age2-waterfront, data=saratoga_train2)

# model1_wo_newConstruction: without newConstruction
model1_wo_newConstruction= lm(price ~ .-rooms-age2-newConstruction, data=saratoga_train2)

# model1_wo_centralAir: without centralAir
model1_wo_centralAir= lm(price ~ .-rooms-age2-centralAir, data=saratoga_train2)

# Predictions out of sample
yhat_test_lotSize = predict(model1_wo_lotSize, saratoga_test2)
yhat_test_age = predict(model1_wo_age, saratoga_test2)
yhat_test_landValue = predict(model1_wo_landValue, saratoga_test2)
yhat_test_livingArea = predict(model1_wo_livingArea, saratoga_test2)
yhat_test_pctCollege = predict(model1_wo_pctCollege, saratoga_test2)
yhat_test_bedrooms = predict(model1_wo_bedrooms, saratoga_test2)
yhat_test_fireplaces = predict(model1_wo_fireplaces, saratoga_test2)
yhat_test_bathrooms = predict(model1_wo_bathrooms, saratoga_test2)
yhat_test_heating = predict(model1_wo_heating, saratoga_test2)
yhat_test_fuel = predict(model1_wo_fuel, saratoga_test2)
yhat_test_sewer = predict(model1_wo_sewer, saratoga_test2)
yhat_test_waterfront = predict(model1_wo_waterfront, saratoga_test2)
yhat_test_newConstruction = predict(model1_wo_newConstruction, saratoga_test2)
yhat_test_centralAir = predict(model1_wo_centralAir, saratoga_test2)

c(rmse(saratoga_test2$price, yhat_test_lotSize), rmse(saratoga_test2$price, yhat_test_age), rmse(saratoga_test2$price, yhat_test_landValue), rmse(saratoga_test2$price, yhat_test_livingArea), rmse(saratoga_test2$price, yhat_test_pctCollege), rmse(saratoga_test2$price, yhat_test_bedrooms), rmse(saratoga_test2$price, yhat_test_fireplaces), rmse(saratoga_test2$price, yhat_test_bathrooms), rmse(saratoga_test2$price, yhat_test_heating), rmse(saratoga_test2$price, yhat_test_fuel), rmse(saratoga_test2$price, yhat_test_sewer), rmse(saratoga_test2$price, yhat_test_waterfront), rmse(saratoga_test2$price, yhat_test_newConstruction), rmse(saratoga_test2$price, yhat_test_centralAir))}

rmse_result2= data.frame("model_wo_lotSize"= colMeans(rmse_check2[1]), "model_wo_age"=colMeans(rmse_check2[2]), "model_wo_landValue"=colMeans(rmse_check2[3]), "model_wo_livingArea"=colMeans(rmse_check2[4]), "model_wo_pctCollege"=colMeans(rmse_check2[5]), "model_wo_bedrooms"=colMeans(rmse_check2[6]), "model_wo_fireplaces"= colMeans(rmse_check2[7]), "model_wo_bathrooms"=colMeans(rmse_check2[8]), "model_wo_heating"=colMeans(rmse_check2[9]), "model_wo_fuel"=colMeans(rmse_check2[10]), "model_wo_sewer"=colMeans(rmse_check2[11]), "model_wo_waterfront"=colMeans(rmse_check2[12]), "model_wo_newConstruction"=colMeans(rmse_check2[13]), "model_wo_centralAir"=colMeans(rmse_check2[14]), row.names="AVG RMSE")

rmse_result2_t = t(rmse_result2)

kable(rmse_result2_t) %>% kable_styling("striped")
```

Now, we build a nonparametic KNN model to compare it with our linear model and figure out which one performs better.
By using the same train and test sets that we used in our linear regression, the result shows that whatever value K may have, the knn model is unlikely to perfrom better than our linear model.
In the graph below, the horizontal red line shows the out-of-sample RMSE of our linear model. We can see that all the RMSEs of the knn model in accordance with k values are plotted above the red line. 
And the table below suggests the fact that the minimum RMSE value of knn model is still bigger than our best-fit linear model. 


```{r 2.1.6, echo=FALSE}
# construct the training and test-set feature matrices
Xtrain= model.matrix(~ .-(price + rooms + age2)-1, data=saratoga_train)
Xtest = model.matrix(~ .-(price + rooms + age2)-1, data= saratoga_test)

# training and testing set responses 
ytrain = saratoga_train$price
ytest = saratoga_test$price

# rescale
scale_train = apply(Xtrain, 2, sd)
Xtilde_train = scale(Xtrain, scale = scale_train)
Xtilde_test = scale(Xtest, scale= scale_train)
K= 10

# fit the model
knn_model = knn.reg(Xtilde_train, Xtilde_test, ytrain, k=K)

k_grid = seq(1,50, by=1)
rmse_grid = foreach(K= k_grid, .combine='c') %do% {
knn_model = knn.reg(Xtilde_train, Xtilde_test, ytrain, k=K)
rmse(ytest, knn_model$pred)
}
plot(k_grid, rmse_grid, ylim=c(55000,80000))
abline(h=rmse(ytest, yhat_test1), col='red')

K= which.min(rmse_grid)
modelcompare = data.frame('Kmin'=K, 'knn model RMSE' = rmse(ytest, knn_model$pred), 'linear model RMSE' = rmse(ytest, yhat_test1))
kable(modelcompare) %>% kable_styling("striped", full_width=F)
```

But there is random variation due to the particular choice of data points that end up in your train/test split. So we run Monte-Carlo simulation again using random train/test split for 100 times, and compare the minimim RMSE of knn model with RMSE of our linear model.
As a result, we can see that our linear model outperforms the knn model.


```{r 2.1.7, echo=FALSE}
rmse_check3 = do(100)*{# Split into training and testing sets
train_cases3 = sample.int(n, n_train, replace=FALSE)
test_cases3 = setdiff(1:n, train_cases3)
saratoga_train3 = SaratogaHouses[train_cases3,]
saratoga_test3 = SaratogaHouses[test_cases3,]

# construct the training and test-set feature matrices
Xtrain3= model.matrix(~ .-(price + rooms + age2)-1, data=saratoga_train3)
Xtest3 = model.matrix(~ .-(price + rooms + age2)-1, data= saratoga_test3)

# training and testing set responses 
ytrain3 = saratoga_train3$price
ytest3 = saratoga_test3$price

# rescale
scale_train3 = apply(Xtrain3, 2, sd)
Xtilde_train3 = scale(Xtrain3, scale = scale_train3)
Xtilde_test3 = scale(Xtest3, scale= scale_train3)
K3=10

# fit the model
knn_model3 = knn.reg(Xtilde_train3, Xtilde_test3, ytrain3, k=K3)


k_grid3 = seq(1,50, by=1)
rmse_grid3 = foreach(K3= k_grid3, .combine='c') %do% {
knn_model3 = knn.reg(Xtilde_train3, Xtilde_test3, ytrain3, k=K3)
rmse(ytest3, knn_model3$pred)}
min(rmse_grid3)
}


modelcompare2 = data.frame("knn_model"= colMeans(rmse_check3), "linear_model"= colMeans(rmse_check[1]), row.names="Average_RMSE")
kable(modelcompare2) %>% kable_styling("striped")

```

